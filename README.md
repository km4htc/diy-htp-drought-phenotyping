# DIY High-throughput drought phenotyping

This repository includes information to recreate both the hardware and software used to perform high-throughput drought phenotyping in *Improving rice drought tolerance through host-mediated microbiome selection* (https://doi.org/10.7554/eLife.97015.1).

Traditional drought phenotyping methods are either low-throughput and/or difficult to perform on individual plants without destructive sampling. Spectroscopy can help to overcome these inefficiencies, e.g. by using patterns of light transmission/reflectance to determine chlorophyll content or to derive vegetation indices, allowing samples to be quickly and non-destrucvtively measured. A number of tools already exist to make such measurements, though none that met the particular needs or budget for our project. For example, handheld tools such as a SPAD meter or Photosynq Multispeq are reasonably priced and are quick data collecters, but only capture data from a small portion of individual leaves and cannot be easily used on droughted plants with leaf curling symptoms. Other tools are meant for remote sensing, and employ drones or other vehicles to carry multi/hyperspectral cameras to scan entire fields; while this approach could  easily be scaled down to measure individual plants, the cameras themselves can be prohibitively expensive. 

With the goal of non-destructively phenotyping severely droughted plants in high throughput, I built my own platform using inexpensive and readily available parts. The platform consists of three parts: 1) a pair of DSLR cameras to perform the "multispectral" imaging, 2) a lightbox to control lighting for each image, and 3) a set of scripts to pair data from the two cameras, segment plants from background, then derive vegetation indices to describe a plant's drought status.

### The cameras
The sensors of typical digital cameras are sensitive to light across both the visible (400-700nm) and near-infrared (700-1300) spectra, though IR exclusion filters overlaying the sensor typically restrict the detection of light to just the visible spectrum. Light passing this filter must additionally pass through a Bayer filter--a mosaic of red, green, and blue filters--that further restrict which wavelengths of light reach the sensor and determine the RGB values for a given pixel in an image. As such, the R or Red value for a pixel represents the intensity of red visible light (~550-650nm) reflecting off the surface of the object being photographed; the Green and Blue values indicate the intensity of visible light within ~500-625nm and ~425-525nm, respectively (though there is overlap in the ranges of the red, green, and blue channels, sensitivity typically peaks in the middle of the range).

However, by removing the IR exclusion filter and replacing it with a dual-pass filter that transmits light between 400-600nm as well as between 700-800nm, the  the Red channel can be shifted to detect longer wavelengths of light, including near-infrared, while Blue and Green channels can be left relatively unaffected. Our cameras, then, included one standard DSLR and one modified with the dual-pass filter described above; by pairing the two cameras, we essentially created a multispectral camera with four channels, Red, Green, Blue, and IR. Both standard and modified cameras were Canon DSLRs, models t7 and t1, respectively, and IR exclusion filter removal and replacement was performed by Life Pixel Infrared. Both cameras were set to: shutter speed = 1/40; F-stop = 4.5; ISO = 100; Effect = Neutral; White balance = 7000K; Auto lighting optimizer = OFF. 

By including IR values in our image data, we were able to derive the Normalized Difference Vegetation Index (NDVI) which is a useful measure of overall plant health and stress status. Simply put, NDVI is a measure of the difference of visible light vs infrared light reflected off a plant's surface. While healthy plants strongly absorb (red and blue) visible light via chlorophyll, more of this light will be reflected as plants become stressed and chlorophyll is lost. IR, on the other hand, tends to be strongly reflected regardless of plant stress status. As such, we quantified NDVI as the sum of the median red values from the standard (STD) and modified (MOD) cameras, i.e. visible red and IR, divided by their difference:
```math
NDVI = {MOD_{red} + STD_{red} \over MOD_{red} - STD_{red}} 
```

### The lightbox
A simple lightbox, a 2'x2'x2' cube constructed from MDF, served to control lighting conditions for each image. We painted the interior with "Black 3.0", an ultra light-absorbing black paint from Culture Hustle USA, to minimize reflectance off the surfaces of the box and used a blackout cloth to prevent light leaking through the box door and holes cut to accomodate camera lenses. We affixed alternating strips of full spectrum and 730nm LED lights the entire length of the wall opposite where plants were to be positioned; importantly, while the modified camera could detect the 730nm red light, the standard camera could not. For ease of loading plants, we added a small track made from drawer slides and a corresponding "drawer" that could be loaded with up to 5 five plants at a time (for this project we also built plywood racks to hold five plants with individual pots and water reservoirs; this could then be loaded directly onto the track). Lastly, because downstream object detection of individual plants within images was most easily accomplished if plants did not overlap one another, we built a simple divider, also painted with Black 3.0, to create a boundary between plants.

